{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e43bda15",
      "metadata": {
        "id": "e43bda15"
      },
      "source": [
        "### Must install Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b79ea239",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b79ea239",
        "outputId": "3e007f2c-3e11-4c71-bbed-363d7dafa1ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.8/331.8 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.4/800.4 KB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip3 install lightning-bolts==0.6.0 --quiet\n",
        "!pip3 install pytorch-lightning==1.8.5 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5e6d27c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e6d27c8",
        "outputId": "1b2561c5-5e65-4c09-99ba-093a31609fd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pl_bolts/callbacks/data_monitor.py:20: UnderReviewWarning: The feature warn_missing_pkg is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  warn_missing_pkg(\"wandb\")\n",
            "/usr/local/lib/python3.8/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:35: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/usr/local/lib/python3.8/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:93: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/usr/local/lib/python3.8/dist-packages/pl_bolts/losses/self_supervised_learning.py:234: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n"
          ]
        }
      ],
      "source": [
        "from torchvision import transforms\n",
        "from pl_bolts.transforms.dataset_normalizations import cifar10_normalization\n",
        "from torchvision.models.resnet import resnet18\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer, LightningModule\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e67630c1",
      "metadata": {
        "id": "e67630c1"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.functional import accuracy\n",
        "from pytorch_lightning.callbacks import Callback\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9ae255cc",
      "metadata": {
        "id": "9ae255cc"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20\n",
        "LR = 0.1\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 5e-4\n",
        "PRINT_FREQ = 50\n",
        "TRAIN_BATCH=128\n",
        "VAL_BATCH=128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bd23499b",
      "metadata": {
        "id": "bd23499b"
      },
      "outputs": [],
      "source": [
        "GPU = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebf682bd",
      "metadata": {
        "id": "ebf682bd"
      },
      "source": [
        "### fill in the transform statements below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d371d08",
      "metadata": {
        "id": "5d371d08"
      },
      "outputs": [],
      "source": [
        "class CIFAR10DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, train_batch_size, val_batch_size, data_dir: str = './'):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.train_batch_size = train_batch_size\n",
        "        self.val_batch_size = val_batch_size\n",
        "        \n",
        "        self.transform_train = ???\n",
        "        self.transform_val = ???\n",
        "        \n",
        "        self.dims = (3, 32, 32)\n",
        "        self.num_classes = 10\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # download \n",
        "        CIFAR10(self.data_dir, train=True, download=True)\n",
        "        CIFAR10(self.data_dir, train=False, download=True)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Assign train/val datasets for use in dataloaders\n",
        "        if stage == 'fit' or stage is None:\n",
        "#            cifar_full = CIFAR10(self.data_dir, train=True, transform=self.transform)\n",
        "#            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])\n",
        "            self.cifar_train = CIFAR10(self.data_dir, train=True, transform=self.transform_train)\n",
        "            self.cifar_val = CIFAR10(self.data_dir, train=False, transform=self.transform_val)\n",
        "\n",
        "        # Assign test dataset for use in dataloader(s)\n",
        "        if stage == 'test' or stage is None:\n",
        "            self.cifar_test = CIFAR10(self.data_dir, train=False, transform=self.transform_val)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.cifar_train, batch_size=self.train_batch_size, num_workers = 2, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.cifar_val, batch_size=self.val_batch_size, num_workers = 2)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.cifar_test, batch_size=self.batch_size, num_workers = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba923c18",
      "metadata": {
        "id": "ba923c18"
      },
      "outputs": [],
      "source": [
        "dm = CIFAR10DataModule(TRAIN_BATCH, VAL_BATCH)\n",
        "dm.prepare_data()\n",
        "dm.setup()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "360a6795",
      "metadata": {
        "id": "360a6795"
      },
      "outputs": [],
      "source": [
        "MODEL_CKPT_PATH = 'model/'\n",
        "MODEL_CKPT = 'model/model-{epoch:02d}-{val_loss:.2f}'\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    filename=MODEL_CKPT ,\n",
        "    save_top_k=3,\n",
        "    mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "261c6d84",
      "metadata": {
        "id": "261c6d84"
      },
      "outputs": [],
      "source": [
        "# Samples required by the custom ImagePredictionLogger callback to log image predictions.\n",
        "val_samples = next(iter(dm.val_dataloader()))\n",
        "val_imgs, val_labels = val_samples[0], val_samples[1]\n",
        "val_imgs.shape, val_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d4af0f4",
      "metadata": {
        "id": "5d4af0f4"
      },
      "outputs": [],
      "source": [
        "early_stop_callback = EarlyStopping(\n",
        "   monitor='val_loss',\n",
        "   patience=3,\n",
        "   verbose=False,\n",
        "   mode='min'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4b5fcb4",
      "metadata": {
        "id": "a4b5fcb4"
      },
      "source": [
        "### Complete the training, validation, and optimizer methods below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "267ab69c",
      "metadata": {
        "id": "267ab69c"
      },
      "outputs": [],
      "source": [
        "class LitResnet18(LightningModule):\n",
        "    def __init__(self, learning_rate, momentum, weight_decay):\n",
        "        super().__init__()\n",
        "        self.nn = resnet18(pretrained = False, progress  = True)\n",
        "        self.nn.fc = nn.Linear(self.nn.fc.in_features, 10)\n",
        "        self.lr = learning_rate\n",
        "        self.momentum = momentum\n",
        "        self.weight_decay = weight_decay\n",
        "        self.criterion = nn.CrossEntropyLoss().cuda(GPU)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.nn.forward(x)\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x,y = batch\n",
        "        logits = self.nn(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        # training metrics\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = accuracy(preds, y, task = \"multiclass\", num_classes = 10)\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=False)\n",
        "        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=False)\n",
        "        if batch_idx % PRINT_FREQ == 0:\n",
        "          print(\"train step! \" + str(batch_idx) + \" train loss: \" + str(loss.item()) + \" train acc \" + str(acc.item()))        \n",
        "        return loss     \n",
        "        \n",
        "        \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x,y = batch\n",
        "        logits = self.nn(x)\n",
        "        loss = self.criterion(logits, y) \n",
        "        # validation metrics\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = accuracy(preds, y, task = \"multiclass\", num_classes = 10)\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', acc, prog_bar=True)\n",
        "        if batch_idx % PRINT_FREQ == 0:\n",
        "          print(\"val step! \" + str(batch_idx) + \" val loss: \" + str(loss.item()) + \" val acc \" + str(acc.item()))\n",
        "        return loss  \n",
        "        \n",
        "        \n",
        "        \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.SGD(model.parameters(), self.lr, momentum=self.momentum, weight_decay=self.weight_decay)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57d9e6ac",
      "metadata": {
        "id": "57d9e6ac"
      },
      "outputs": [],
      "source": [
        "# model = resnet18(pretrained = False, progress  = True)\n",
        "model = LitResnet18(LR, MOMENTUM, WEIGHT_DECAY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efa89962",
      "metadata": {
        "id": "efa89962"
      },
      "outputs": [],
      "source": [
        "# Initialize a trainer\n",
        "trainer = pl.Trainer(max_epochs=EPOCHS,\n",
        "                     gpus=1, \n",
        "                     logger=None,\n",
        "                     callbacks=[early_stop_callback, checkpoint_callback],\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d19630c1",
      "metadata": {
        "id": "d19630c1"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model, dm)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}